{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import ensemble, linear_model, preprocessing, neighbors, datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve, auc, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We're dealing with a multiclass classification problem with 5 possible target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (51336, 7)\n",
      "X_test shape: (12834, 7)\n",
      "y_train shape: (51336,)\n",
      "y_test shape: (12834,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51336 entries, 0 to 51335\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   number_reviews_scaled    51336 non-null  float64\n",
      " 1   review_time_encoded      51336 non-null  int64  \n",
      " 2   text_word_length_scaled  51336 non-null  float64\n",
      " 3   Sentiment_VADER          51336 non-null  float64\n",
      " 4   Sentiment_Blob           51336 non-null  float64\n",
      " 5   bow_1920                 51336 non-null  int64  \n",
      " 6   local_hour               51336 non-null  int64  \n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 2.7 MB\n",
      "X_train info: None\n",
      "X_train dtypes: number_reviews_scaled      float64\n",
      "review_time_encoded          int64\n",
      "text_word_length_scaled    float64\n",
      "Sentiment_VADER            float64\n",
      "Sentiment_Blob             float64\n",
      "bow_1920                     int64\n",
      "local_hour                   int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_reviews_scaled</th>\n",
       "      <th>review_time_encoded</th>\n",
       "      <th>text_word_length_scaled</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>bow_1920</th>\n",
       "      <th>local_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.261191</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494554</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790268</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>-0.087500</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.089733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369684</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089733</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.103473</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.208619</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_reviews_scaled  review_time_encoded  text_word_length_scaled  \\\n",
       "0              -0.674019                    1                -0.261191   \n",
       "1               0.494554                    1                 0.790268   \n",
       "2              -0.089733                    0                 0.369684   \n",
       "3              -0.089733                    1                -0.103473   \n",
       "4               2.247413                    1                -0.208619   \n",
       "\n",
       "   Sentiment_VADER  Sentiment_Blob  bow_1920  local_hour  \n",
       "0           0.0000        0.125000         0           7  \n",
       "1           0.2732       -0.087500         1           8  \n",
       "2           0.5994        0.386667         0           9  \n",
       "3           0.9584        0.436111         0           6  \n",
       "4           0.4019       -0.033333         0          11  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the datasets\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"X_train info:\", X_train.info())\n",
    "print(\"X_train dtypes:\", X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_reviews_scaled</th>\n",
       "      <th>review_time_encoded</th>\n",
       "      <th>text_word_length_scaled</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>bow_1920</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>1</td>\n",
       "      <td>2.367457</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.125556</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.629202</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>-0.445833</td>\n",
       "      <td>0</td>\n",
       "      <td>1.366770</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.089733</td>\n",
       "      <td>1</td>\n",
       "      <td>2.104592</td>\n",
       "      <td>-0.8011</td>\n",
       "      <td>-0.062143</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.477486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.158279</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.887320</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159392</td>\n",
       "      <td>-0.6324</td>\n",
       "      <td>0.057653</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.682403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_reviews_scaled  review_time_encoded  text_word_length_scaled  \\\n",
       "0               2.247413                    1                 2.367457   \n",
       "1              -0.674019                    1                -0.629202   \n",
       "2              -0.089733                    1                 2.104592   \n",
       "3              -0.674019                    1                 1.158279   \n",
       "4              -0.674019                    1                 0.159392   \n",
       "\n",
       "   Sentiment_VADER  Sentiment_Blob  bow_1920  local_hour  rating  \n",
       "0           0.7806        0.125556         0   -0.272568       1  \n",
       "1          -0.2263       -0.445833         0    1.366770       3  \n",
       "2          -0.8011       -0.062143         0   -0.477486       1  \n",
       "3           0.9698        0.283333         0   -0.887320       5  \n",
       "4          -0.6324        0.057653         0   -0.682403       3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One: 20.0 %\n",
      "Number of one ratings: 4313\n",
      "Two: 20.0 %\n",
      "Number of two ratings: 4313\n",
      "Three: 20.0 %\n",
      "Number of three ratings: 4313\n",
      "Four: 20.0 %\n",
      "Number of four ratings: 4313\n",
      "Five: 20.0 %\n",
      "Number of five ratings: 4313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_reviews_scaled</th>\n",
       "      <th>review_time_encoded</th>\n",
       "      <th>text_word_length_scaled</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>bow_1920</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>1</td>\n",
       "      <td>2.367457</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.125556</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.629202</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>-0.445833</td>\n",
       "      <td>0</td>\n",
       "      <td>1.353202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.089733</td>\n",
       "      <td>1</td>\n",
       "      <td>2.104592</td>\n",
       "      <td>-0.8011</td>\n",
       "      <td>-0.062143</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.455637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.158279</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.857601</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159392</td>\n",
       "      <td>-0.6324</td>\n",
       "      <td>0.057653</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.656619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_reviews_scaled  review_time_encoded  text_word_length_scaled  \\\n",
       "0               2.247413                    1                 2.367457   \n",
       "1              -0.674019                    1                -0.629202   \n",
       "2              -0.089733                    1                 2.104592   \n",
       "3              -0.674019                    1                 1.158279   \n",
       "4              -0.674019                    1                 0.159392   \n",
       "\n",
       "   Sentiment_VADER  Sentiment_Blob  bow_1920  local_hour  rating  \n",
       "0           0.7806        0.125556         0   -0.254655       1  \n",
       "1          -0.2263       -0.445833         0    1.353202       3  \n",
       "2          -0.8011       -0.062143         0   -0.455637       1  \n",
       "3           0.9698        0.283333         0   -0.857601       5  \n",
       "4          -0.6324        0.057653         0   -0.656619       3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1: 20.00% Number of ratings: 4313\n",
      "Rating 2: 20.00% Number of ratings: 4313\n",
      "Rating 3: 20.00% Number of ratings: 4313\n",
      "Rating 4: 20.00% Number of ratings: 4313\n",
      "Rating 5: 20.00% Number of ratings: 4313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_reviews_scaled</th>\n",
       "      <th>review_time_encoded</th>\n",
       "      <th>text_word_length_scaled</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>bow_1920</th>\n",
       "      <th>local_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12058</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>-0.6604</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.058583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>-0.089733</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.944640</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.755166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20704</th>\n",
       "      <td>-0.674019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.576629</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.455637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20528</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211965</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>2.247413</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.313764</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_reviews_scaled  review_time_encoded  text_word_length_scaled  \\\n",
       "12058               2.247413                    0                 1.000560   \n",
       "7303               -0.089733                    0                -0.944640   \n",
       "20704              -0.674019                    0                -0.576629   \n",
       "20528               2.247413                    1                 0.211965   \n",
       "5872                2.247413                    1                -0.313764   \n",
       "\n",
       "       Sentiment_VADER  Sentiment_Blob  bow_1920  local_hour  \n",
       "12058          -0.6604        0.075000         0   -1.058583  \n",
       "7303            0.0000        0.000000         0    1.755166  \n",
       "20704          -0.1531        0.000000         0   -0.455637  \n",
       "20528           0.3818        0.225000         0   -0.254655  \n",
       "5872           -0.3612        0.416667         0    0.147309  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17252, 7)\n"
     ]
    }
   ],
   "source": [
    "#Anomaly detection\n",
    "\n",
    "#Rejoin dataset\n",
    "X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "y_combined = pd.concat([y_train, y_test], axis=0)\n",
    "X_combined.reset_index(drop=True, inplace=True)\n",
    "y_combined.reset_index(drop=True, inplace=True)\n",
    "df_trustpilot = X_combined.copy()\n",
    "df_trustpilot['rating'] = y_combined\n",
    "df_trustpilot.reset_index(drop=True, inplace=True)\n",
    "display(df_trustpilot.head())\n",
    "\n",
    "#Display proportions\n",
    "all = len(df_trustpilot)\n",
    "one = df_trustpilot[df_trustpilot['rating'] == 1]\n",
    "two = df_trustpilot[df_trustpilot['rating'] == 2]\n",
    "three = df_trustpilot[df_trustpilot['rating'] == 3]\n",
    "four = df_trustpilot[df_trustpilot['rating'] == 4]\n",
    "five = df_trustpilot[df_trustpilot['rating'] == 5]\n",
    "one_p = len(one)/all\n",
    "two_p = len(two)/all\n",
    "three_p = len(three)/all\n",
    "four_p = len(four)/all\n",
    "five_p = len(five)/all\n",
    "print('One:',one_p*100,'%')\n",
    "print(\"Number of one ratings:\", len(one))\n",
    "print('Two:',two_p*100,'%')\n",
    "print(\"Number of two ratings:\", len(two))\n",
    "print('Three:',three_p*100,'%')\n",
    "print(\"Number of three ratings:\", len(three))\n",
    "print('Four:',four_p*100,'%')\n",
    "print(\"Number of four ratings:\", len(four))\n",
    "print('Five:',five_p*100,'%')\n",
    "print(\"Number of five ratings:\", len(five))\n",
    "\n",
    "#Normalize the last feature\n",
    "df_trustpilot['local_hour'] = StandardScaler().fit_transform(df_trustpilot['local_hour'].values.reshape(-1,1))\n",
    "display(df_trustpilot.head())\n",
    "\n",
    "#Rebalance the dataset\n",
    "df_balanced = df_trustpilot.sample(frac=1, random_state=42)\n",
    "rating_1 = df_balanced[df_balanced['rating'] == 1][:4313] \n",
    "rating_2 = df_balanced[df_balanced['rating'] == 2][:4313]      \n",
    "rating_3 = df_balanced[df_balanced['rating'] == 3][:4313]  \n",
    "rating_4 = df_balanced[df_balanced['rating'] == 4][:4313]  \n",
    "rating_5 = df_balanced[df_balanced['rating'] == 5][:4313]  \n",
    "df_balanced_final = pd.concat([rating_1, rating_2, rating_3, rating_4, rating_5])\n",
    "df_balanced_final = df_balanced_final.sample(frac=1, random_state=42)\n",
    "labels = ['Rating 1', 'Rating 2', 'Rating 3', 'Rating 4', 'Rating 5']\n",
    "classes = pd.value_counts(df_balanced_final['rating'], sort=True)\n",
    "classes.plot(kind='bar', rot=0)\n",
    "plt.title(\"Rating Distribution After Balancing\")\n",
    "plt.xticks(range(5), labels)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "for rating in range(1, 6):\n",
    "    count = len(df_balanced_final[df_balanced_final['rating'] == rating])\n",
    "    percentage = (count / len(df_balanced_final)) * 100\n",
    "    print(f\"Rating {rating}: {percentage:.2f}% Number of ratings: {count}\")\n",
    "\n",
    "X = df_balanced_final.drop('rating', axis=1)\n",
    "y = df_balanced_final['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)\n",
    "\n",
    "display(X.head())\n",
    "print(X_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomaly detection code - testing base model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "\n",
    "#Dataset modifications\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "y_combined = pd.concat([y_train, y_test], axis=0)\n",
    "X_combined.reset_index(drop=True, inplace=True)\n",
    "y_combined.reset_index(drop=True, inplace=True)\n",
    "df_trustpilot = X_combined.copy()\n",
    "df_trustpilot['rating'] = y_combined\n",
    "df_trustpilot.reset_index(drop=True, inplace=True)\n",
    "display(df_trustpilot.head())\n",
    "all = len(df_trustpilot)\n",
    "one = df_trustpilot[df_trustpilot['rating'] == 1]\n",
    "two = df_trustpilot[df_trustpilot['rating'] == 2]\n",
    "three = df_trustpilot[df_trustpilot['rating'] == 3]\n",
    "four = df_trustpilot[df_trustpilot['rating'] == 4]\n",
    "five = df_trustpilot[df_trustpilot['rating'] == 5]\n",
    "one_p = len(one)/all\n",
    "two_p = len(two)/all\n",
    "three_p = len(three)/all\n",
    "four_p = len(four)/all\n",
    "five_p = len(five)/all\n",
    "print('One:',one_p*100,'%')\n",
    "print(\"Number of one ratings:\", len(one))\n",
    "print('Two:',two_p*100,'%')\n",
    "print(\"Number of two ratings:\", len(two))\n",
    "print('Three:',three_p*100,'%')\n",
    "print(\"Number of three ratings:\", len(three))\n",
    "print('Four:',four_p*100,'%')\n",
    "print(\"Number of four ratings:\", len(four))\n",
    "print('Five:',five_p*100,'%')\n",
    "print(\"Number of five ratings:\", len(five))\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Rebalance the dataset\n",
    "df_balanced = df_trustpilot.sample(frac=1, random_state=42)\n",
    "rating_1 = df_balanced[df_balanced['rating'] == 1][:4313] \n",
    "rating_2 = df_balanced[df_balanced['rating'] == 2][:4313]      \n",
    "rating_3 = df_balanced[df_balanced['rating'] == 3][:4313]  \n",
    "rating_4 = df_balanced[df_balanced['rating'] == 4][:4313]  \n",
    "rating_5 = df_balanced[df_balanced['rating'] == 5][:4313]  \n",
    "df_balanced_final = pd.concat([rating_1, rating_2, rating_3, rating_4, rating_5])\n",
    "df_balanced_final = df_balanced_final.sample(frac=1, random_state=42)\n",
    "labels = ['Rating 1', 'Rating 2', 'Rating 3', 'Rating 4', 'Rating 5']\n",
    "classes = pd.value_counts(df_balanced_final['rating'], sort=True)\n",
    "classes.plot(kind='bar', rot=0)\n",
    "plt.title(\"Rating Distribution After Balancing\")\n",
    "plt.xticks(range(5), labels)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "for rating in range(1, 6):\n",
    "    count = len(df_balanced_final[df_balanced_final['rating'] == rating])\n",
    "    percentage = (count / len(df_balanced_final)) * 100\n",
    "    print(f\"Rating {rating}: {percentage:.2f}% Number of ratings: {count}\")\n",
    "X = df_balanced_final.drop('rating', axis=1)\n",
    "y = df_balanced_final['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Base Model parameters found: {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Best Base Model cross-validation score: 0.42440570501744573\n",
      "Accuracy Base Model:  57.55025712949977 %\n",
      "Balanced Accuracy Base Model:  43.24908905184519 %\n",
      "ROC AUC Base Model:  79.20198971687297 %\n",
      "Classification Report Base Model:  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.63      0.68      3188\n",
      "           2       0.17      0.23      0.20       863\n",
      "           3       0.23      0.31      0.26      1254\n",
      "           4       0.17      0.29      0.22      1257\n",
      "           5       0.85      0.71      0.77      6272\n",
      "\n",
      "    accuracy                           0.58     12834\n",
      "   macro avg       0.43      0.43      0.43     12834\n",
      "weighted avg       0.65      0.58      0.61     12834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Non-anomaly detection code - testing base model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-anomaly detection code - testing base model with Random Oversampling\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Apply Random Oversampling\n",
    "ros = RandomOverSampler(random_state=25)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after oversampling:\", dict(pd.Series(y_train).value_counts()))\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-anomaly detection code - testing base model with Random Undersampling\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Apply Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=25)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after oversampling:\", dict(pd.Series(y_train).value_counts()))\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-anomaly detection code - testing base model with SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Apply SMOTE\n",
    "smo = SMOTE()\n",
    "X_train, y_train = smo.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after oversampling:\", dict(pd.Series(y_train).value_counts()))\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-anomaly detection code - testing base model with SMOTETomek\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Apply Random SMOTETomek\n",
    "smt = SMOTETomek()\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after oversampling:\", dict(pd.Series(y_train).value_counts()))\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-anomaly detection code - testing base model with ClusterCentroids\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "X_train = pd.read_csv('data/X_train.csv', engine='python')\n",
    "X_test = pd.read_csv('data/X_test.csv', engine='python')\n",
    "y_train = pd.read_csv('data/y_train.csv', engine='python')['rating']\n",
    "y_test = pd.read_csv('data/y_test.csv', engine='python')['rating']\n",
    "\n",
    "#Scale local_hour\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "#Apply Random SMOTETomek\n",
    "cc = ClusterCentroids()\n",
    "X_train, y_train = cc.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after oversampling:\", dict(pd.Series(y_train).value_counts()))\n",
    "\n",
    "#Base model - Logistic regression\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "custom_weights = {1: 2.0, 2: 7.0, 3: 5.0, 4: 5.0, 5: 1.0}\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1], 'class_weight': ['balanced', 'balanced_subsample'], 'solver': ['lbfgs'], 'max_iter': [100, 200, 500]}\n",
    "param_grid_lr['class_weight'].append(custom_weights)\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=25, max_iter=2000), param_grid_lr, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "print(\"Best Base Model parameters found:\", grid_search_lr.best_params_)\n",
    "print(\"Best Base Model cross-validation score:\", grid_search_lr.best_score_)\n",
    "\n",
    "model = LogisticRegression(**grid_search_lr.best_params_, random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "base_model_score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "base_model_cr = classification_report(y_test, y_pred)\n",
    "base_model_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "base_model_balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Base Model: \", base_model_score * 100, \"%\")\n",
    "print(\"Balanced Accuracy Base Model: \", base_model_balanced_accuracy * 100, \"%\")\n",
    "print(\"ROC AUC Base Model: \", base_model_roc_auc * 100, \"%\")\n",
    "print(\"Classification Report Base Model: \", \"\\n\", base_model_cr)\n",
    "\n",
    "#Bagging Classifier\n",
    "param_grid_bc = {'n_estimators': [400, 500, 600], 'max_samples': [0.5, 0.6, 0.7], 'max_features': [0.4, 0.5, 0.6], 'bootstrap_features': [True, False]}\n",
    "grid_search_bc = GridSearchCV(BaggingClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25), bootstrap=True, n_jobs=-1, random_state=25),\n",
    "    param_grid_bc, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_bc.fit(X_train, y_train)\n",
    "print(\"Best Bagging Classifier parameters:\", grid_search_bc.best_params_)\n",
    "print(\"Best Bagging Classifier cross-validation score:\", grid_search_bc.best_score_)\n",
    "\n",
    "bc = BaggingClassifier(estimator=model, **grid_search_bc.best_params_, bootstrap=True, n_jobs=-1, random_state=25)\n",
    "bc.fit(X_train, y_train)\n",
    "score_bc = bc.score(X_test, y_test)\n",
    "y_pred_bc = bc.predict(X_test)\n",
    "cr_bc = classification_report(y_test, y_pred_bc)\n",
    "balanced_accuracy_bc = balanced_accuracy_score(y_test, y_pred_bc)\n",
    "roc_auc_bc = roc_auc_score(y_test, bc.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Bagging Classifier: \", score_bc * 100, \"%\")\n",
    "print(\"Balanced Accuracy Bagging Classifier: \", balanced_accuracy_bc * 100, \"%\")\n",
    "print(\"ROC AUC Bagging Classifier: \", roc_auc_bc * 100, \"%\")\n",
    "print(\"Classification Report Bagging Classifier: \", \"\\n\", cr_bc)\n",
    "\n",
    "#Adaptive Boosting\n",
    "param_grid_ac = {'n_estimators': [10, 50, 100], 'learning_rate': [0.001, 0.01, 0.1], 'algorithm': ['SAMME']}\n",
    "grid_search_ac = GridSearchCV(AdaBoostClassifier(estimator=LogisticRegression(**grid_search_lr.best_params_, random_state=25),random_state=25),\n",
    "    param_grid_ac, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_ac.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost parameters:\", grid_search_ac.best_params_)\n",
    "print(\"Best AdaBoost score:\", grid_search_ac.best_score_)\n",
    "\n",
    "ac = AdaBoostClassifier(estimator=model, **grid_search_ac.best_params_, random_state=25)\n",
    "ac.fit(X_train, y_train)\n",
    "score_ac = ac.score(X_test, y_test)\n",
    "y_pred_ac = ac.predict(X_test)\n",
    "cr_ac = classification_report(y_test, y_pred_ac)\n",
    "balanced_accuracy_ac = balanced_accuracy_score(y_test, y_pred_ac)\n",
    "roc_auc_ac = roc_auc_score(y_test, ac.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Adaptive Boosting Classifier: \", score_ac * 100, \"%\")\n",
    "print(\"Balanced Accuracy Adaptive Boosting Classifier: \", balanced_accuracy_ac * 100, \"%\")\n",
    "print(\"ROC AUC Adaptive Boosting Classifier: \", roc_auc_ac * 100, \"%\")\n",
    "print(\"Classification Report Adaptive Boosting Classifier: \", \"\\n\", cr_ac)\n",
    "\n",
    "#Gradient Boosting Classifier\n",
    "param_grid_gb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'subsample': [0.8, 1.0]}\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=25),\n",
    "    param_grid_gb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(\"Best Gradient Boosting parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best Gradient Boosting score:\", grid_search_gb.best_score_)\n",
    "\n",
    "gb = GradientBoostingClassifier(**grid_search_gb.best_params_, random_state=25)\n",
    "gb.fit(X_train, y_train)\n",
    "score_gb = gb.score(X_test, y_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "cr_gb = classification_report(y_test, y_pred_gb)\n",
    "balanced_accuracy_gb = balanced_accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Gradient Boosting Classifier: \", score_gb * 100, \"%\")\n",
    "print(\"Balanced Accuracy Gradient Boosting Classifier: \", balanced_accuracy_gb * 100, \"%\")\n",
    "print(\"ROC AUC Gradient Boosting Classifier: \", roc_auc_gb * 100, \"%\")\n",
    "print(\"Classification Report Gradient Boosting Classifier: \", \"\\n\", cr_gb)\n",
    "\n",
    "#LightGBM Classifier\n",
    "param_grid_lgb = {'n_estimators': [200, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5], 'num_leaves': [31, 127], 'subsample': [0.8, 1.0]}\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=25, objective='multiclass'),\n",
    "    param_grid_lgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "print(\"Best LightGBM parameters:\", grid_search_lgb.best_params_)\n",
    "print(\"Best LightGBM score:\", grid_search_lgb.best_score_)\n",
    "\n",
    "lgb = LGBMClassifier(**grid_search_lgb.best_params_, random_state=25, objective='multiclass')\n",
    "lgb.fit(X_train, y_train)\n",
    "score_lgb = lgb.score(X_test, y_test)\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "cr_lgb = classification_report(y_test, y_pred_lgb)\n",
    "balanced_accuracy_lgb = balanced_accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, lgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy LightGBM Classifier: \", score_lgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy LightGBM Classifier: \", balanced_accuracy_lgb * 100, \"%\")\n",
    "print(\"ROC AUC LightGBM Classifier: \", roc_auc_lgb * 100, \"%\")\n",
    "print(\"Classification Report LightGBM Classifier: \", \"\\n\", cr_lgb)\n",
    "\n",
    "#Balanced Random Forest Classifier\n",
    "param_grid_brf = {'n_estimators': [300], 'max_depth': [4, 5], 'min_samples_split': [2, 3], 'min_samples_leaf': [1], 'sampling_strategy': ['auto', 'all']}\n",
    "grid_search_brf = GridSearchCV(BalancedRandomForestClassifier(random_state=25),\n",
    "    param_grid_brf, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_brf.fit(X_train, y_train)\n",
    "print(\"Best Balanced Random Forest parameters:\", grid_search_brf.best_params_)\n",
    "print(\"Best Balanced Random Forest score:\", grid_search_brf.best_score_)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(**grid_search_brf.best_params_, random_state=25)\n",
    "brf.fit(X_train, y_train)\n",
    "score_brf = brf.score(X_test, y_test)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "cr_brf = classification_report(y_test, y_pred_brf)\n",
    "balanced_accuracy_brf = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "roc_auc_brf = roc_auc_score(y_test, brf.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy Balanced Random Forest Classifier: \", score_brf * 100, \"%\")\n",
    "print(\"Balanced Accuracy Balanced Random Forest Classifier: \", balanced_accuracy_brf * 100, \"%\")\n",
    "print(\"ROC AUC Balanced Random Forest Classifier: \", roc_auc_brf * 100, \"%\")\n",
    "print(\"Classification Report Balanced Random Forest Classifier: \", \"\\n\", cr_brf)\n",
    "\n",
    "#XGBoost Classifier\n",
    "param_grid_xgb = {'n_estimators': [300], 'learning_rate': [0.1], 'max_depth': [4, 5], 'min_child_weight': [1, 2], 'subsample': [0.5, 0.8]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=5, random_state=25),\n",
    "    param_grid_xgb, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train - 1)\n",
    "print(\"Best XGBoost parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost score:\", grid_search_xgb.best_score_)\n",
    "\n",
    "xgb = XGBClassifier(**grid_search_xgb.best_params_, objective='multi:softprob', num_class=5, random_state=25)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "score_xgb = xgb.score(X_test, y_test - 1)\n",
    "y_pred_xgb = xgb.predict(X_test) + 1  \n",
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "balanced_accuracy_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "print(\"Accuracy XGBoost Classifier: \", score_xgb * 100, \"%\")\n",
    "print(\"Balanced Accuracy XGBoost Classifier: \", balanced_accuracy_xgb * 100, \"%\")\n",
    "print(\"ROC AUC XGBoost Classifier: \", roc_auc_xgb * 100, \"%\")\n",
    "print(\"Classification Report XGBoost Classifier: \", \"\\n\", cr_xgb)\n",
    "\n",
    "#Initialize base classifiers\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#Voting Classifier\n",
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], voting='hard')\n",
    "vclf.fit(X_train, y_train)\n",
    "score_vclf = vclf.score(X_test, y_test)\n",
    "y_pred_vclf = vclf.predict(X_test)\n",
    "cr_vclf = classification_report(y_test, y_pred_vclf)\n",
    "balanced_accuracy_vclf = balanced_accuracy_score(y_test, y_pred_vclf)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", score_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Balanced Accuracy:\", balanced_accuracy_vclf * 100, \"%\")\n",
    "print(\"Voting Classifier Classification Report:\\n\", cr_vclf)\n",
    "\n",
    "#Stacking Classifier\n",
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', model)], final_estimator=LogisticRegression(random_state=25), cv=5)\n",
    "sclf.fit(X_train, y_train)\n",
    "score_sclf = sclf.score(X_test, y_test)\n",
    "y_pred_sclf = sclf.predict(X_test)\n",
    "cr_sclf = classification_report(y_test, y_pred_sclf)\n",
    "balanced_accuracy_sclf = balanced_accuracy_score(y_test, y_pred_sclf)\n",
    "\n",
    "print(\"\\nStacking Classifier Accuracy:\", score_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Balanced Accuracy:\", balanced_accuracy_sclf * 100, \"%\")\n",
    "print(\"Stacking Classifier Classification Report:\\n\", cr_sclf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
